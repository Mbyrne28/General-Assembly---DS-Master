{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/data/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing, metrics\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITES_URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the Wine Quality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "whites = pd.read_csv(WHITES_URL, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a new variable 'good_quality' for whites with quality >= 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "whites['good_quality'] = whites.quality >= 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = whites.drop(['quality', 'good_quality'], axis=1).get_values()\n",
    "y = whites.good_quality.astype('int').get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input layer feeding into hidden layer with 5 neurons (sigmoid activation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.add(Dense(input_dim=X.shape[1], units=5, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden layer feeding into a single output neuron (sigmoid activation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use logistic loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect weights before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.39481741, -0.09536666, -0.34531477,  0.43817371, -0.07781047],\n",
       "        [-0.27063367,  0.17226714,  0.23442703,  0.3716563 , -0.01751077],\n",
       "        [ 0.60730034, -0.52558172, -0.47341412, -0.05066514, -0.30108669],\n",
       "        [-0.35363188, -0.60226393, -0.47207981, -0.31543466,  0.24387956],\n",
       "        [-0.12141952,  0.60060877,  0.22250259, -0.50063074,  0.21751952],\n",
       "        [ 0.12847966, -0.30485454,  0.2635119 ,  0.24997938,  0.56377   ],\n",
       "        [-0.4788934 , -0.07476783,  0.58518356,  0.57378525,  0.15224367],\n",
       "        [ 0.05944139, -0.05845046, -0.59787005,  0.3787601 , -0.47948557],\n",
       "        [-0.53848195, -0.01631957, -0.506778  ,  0.17272645,  0.18484467],\n",
       "        [-0.56341803,  0.04864138,  0.58080345,  0.01851743, -0.41355652],\n",
       "        [-0.16350371, -0.43215483, -0.54295194,  0.27082348, -0.01351953]], dtype=float32),\n",
       " array([ 0.,  0.,  0.,  0.,  0.], dtype=float32),\n",
       " array([[-0.38505125],\n",
       "        [ 0.7230866 ],\n",
       "        [ 0.67454004],\n",
       "        [-0.46705604],\n",
       "        [-0.60555148]], dtype=float32),\n",
       " array([ 0.], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3918 samples, validate on 980 samples\n",
      "Epoch 1/10\n",
      "3918/3918 [==============================] - 1s 201us/step - loss: 0.5785 - val_loss: 0.5060\n",
      "Epoch 2/10\n",
      "3918/3918 [==============================] - 1s 174us/step - loss: 0.4836 - val_loss: 0.4655\n",
      "Epoch 3/10\n",
      "3918/3918 [==============================] - 1s 167us/step - loss: 0.4578 - val_loss: 0.4609\n",
      "Epoch 4/10\n",
      "3918/3918 [==============================] - 1s 191us/step - loss: 0.4447 - val_loss: 0.4568\n",
      "Epoch 5/10\n",
      "3918/3918 [==============================] - 1s 179us/step - loss: 0.4368 - val_loss: 0.4581\n",
      "Epoch 6/10\n",
      "3918/3918 [==============================] - 1s 184us/step - loss: 0.4316 - val_loss: 0.4537\n",
      "Epoch 7/10\n",
      "3918/3918 [==============================] - 1s 210us/step - loss: 0.4283 - val_loss: 0.4572\n",
      "Epoch 8/10\n",
      "3918/3918 [==============================] - 1s 160us/step - loss: 0.4259 - val_loss: 0.4552\n",
      "Epoch 9/10\n",
      "3918/3918 [==============================] - 1s 148us/step - loss: 0.4242 - val_loss: 0.4573\n",
      "Epoch 10/10\n",
      "3918/3918 [==============================] - 1s 129us/step - loss: 0.4228 - val_loss: 0.4534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0cfaee6470>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(X_scaled, y, batch_size=10, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect weights after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.46730253, -0.25932771, -0.2482001 ,  0.28815857, -0.05317896],\n",
       "        [ 0.28671721, -0.03101387,  0.06832395,  0.48858953,  0.314358  ],\n",
       "        [ 0.24939002, -0.32514063, -0.32678801, -0.11232706, -0.33844876],\n",
       "        [-0.86731565, -0.18484761,  0.07541508, -0.71438622, -0.23721087],\n",
       "        [ 0.42230424, -0.13751331, -0.38920203,  0.24901353,  0.96934646],\n",
       "        [-0.33335617,  0.19384745,  0.59140205, -0.34260234, -0.10526759],\n",
       "        [-0.24479507, -0.38386905,  0.29488182,  0.71982318,  0.32430506],\n",
       "        [ 0.45991471, -0.64742208, -1.01590288,  0.95318621,  0.05372089],\n",
       "        [-0.65589345,  0.32255822, -0.18556926, -0.24852893, -0.13769718],\n",
       "        [-0.37784705, -0.05710353,  0.38769904,  0.04424203, -0.35806829],\n",
       "        [-1.05682719,  0.61235577,  0.45069709, -0.87809122, -1.16391683]], dtype=float32),\n",
       " array([ 0.39043808, -0.28668246, -0.31193611,  0.27393454,  0.27254069], dtype=float32),\n",
       " array([[-1.12472224],\n",
       "        [ 0.55171263],\n",
       "        [ 0.56339717],\n",
       "        [-1.08073163],\n",
       "        [-1.21508276]], dtype=float32),\n",
       " array([-0.19249871], dtype=float32)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use network to predict probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = nn.predict(X_scaled)[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78480094782070053"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y, pred_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
